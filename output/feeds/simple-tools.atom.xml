<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>the decision blog - simple tools</title><link href="https://calculensis.github.io/" rel="alternate"></link><link href="https://calculensis.github.io/feeds/simple-tools.atom.xml" rel="self"></link><id>https://calculensis.github.io/</id><updated>2023-03-06T00:00:00-05:00</updated><entry><title>a graphical approach to bayes' theorem using trees</title><link href="https://calculensis.github.io/a%20graphical%20approach%20to%20bayes'%20theorem%20using%20trees.html" rel="alternate"></link><published>2023-03-06T00:00:00-05:00</published><updated>2023-03-06T00:00:00-05:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2023-03-06:/a graphical approach to bayes' theorem using trees.html</id><summary type="html">&lt;p&gt;we use a historical example to illustrate a graphical tree approach to bayes' equation for updating beliefs in light of new evidence&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="./images/harmonices.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;In this article I'd like to illustrate an intuitive graphical approach to using Bayes' equation, which itself is a tree diagram. As a concrete example, let's suppose you are, for some strange reason, being taught science in chronological order. You've learned all about the Ptolemaic model, which places Earth in the center of the universe; you haven't gotten to anything later yet, so this is the correct model as far as you know. &lt;/p&gt;
&lt;p&gt;To make this imaginative exercise easier, let's take a moment to consider why the Ptolemaic model was at one time as persuasive as it was.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/north_star.jpg" width="250"/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you look up at the north pole, all the other stars in the sky seem to make one full circle around it every 24 hours, giving the impression that the whole universe is like a great big hollow sphere with little glowing dots painted on the inside of it, which rotates as the Earth sits motionless at its center.&lt;/li&gt;
&lt;li&gt;We could say that Earth is what's rotating instead, but it would have to rotate such that we would be traveling at 1,000 mph! Wouldn't we notice that? Why don't we fly off into space, like water flies off a spinning umbrella?&lt;/li&gt;
&lt;li&gt;The idea of the Earth moving around the Sun seems crazy for similar reasons: If it's flying through space, why don't we fall off and get left behind?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hopefully it's a little clearer now why you might believe that the universe looks like the ancients thought it did (except for Aristarchus, the great ancient astronomer who got it right, putting the sun in the center). &lt;/p&gt;
&lt;p&gt;&lt;img src="./images/orbes.jpg" width="250"/&gt;&lt;/p&gt;
&lt;p&gt;There is still a problem for this model when it comes to the planets. If you watch a planet for long enough as it travels through the night sky, its path will double back on itself, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/wanderer.jpg" width="250"/&gt;&lt;/p&gt;
&lt;p&gt;It's impossible to obtain a trajectory like that if the planets simply travel in circles around the Earth. In fact, the word "planet" comes from a Greek word meaning "wanderer," because the planets seem to wander aimlessly compared to the stars. One way of solving this problem is to introduce epicycles: The planet moves on the rim of a circle, the epicycle, and the center of the epicycle moves in a circle around the Earth. The planets-on-epicycles construction can reproduce the periodic, wandering retrograde motion that we observe.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/epicycle.jpg" width="250"/&gt;&lt;/p&gt;
&lt;p&gt;Now we fast forward from the ancient Greeks to the 17th century. The astronomer Tycho Brahe has made many measurements of the positions of the known planets as they move through the sky, and they say he's done it with unprecedented accuracy! Furthermore, a mathematician named Johannes Kepler has analyzed the data and determined that the simplest way to represent planets' motion is... to have all of them, including Earth, move along ellipses that have the sun at one focus! &lt;/p&gt;
&lt;p&gt;Furthermore, Galileo has discovered the law of inertia: That the natural state of motion for an object is not to slow down and remain at rest, but to keep moving in the same direction at a constant speed. Just like, if you drop a ball while you're standing inside a train traveling on a straight track at a constant speed, it will fall straight toward your feet and not backward, in the same way we can travel along with the Earth as it flies through space without being left behind. &lt;/p&gt;
&lt;p&gt;So we have some belief updating to do! Let's represent the relevant claims with letters:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(P =\)&lt;/span&gt; The Ptolemaic system is the correct model&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(K =\)&lt;/span&gt; Kepler's system is the correct model&lt;/p&gt;
&lt;p&gt;To keep things simple, we'll also suppose that one or the other of these has to be true, so if we write &lt;span class="math"&gt;\(\sim P\)&lt;/span&gt; to mean "&lt;span class="math"&gt;\(P\)&lt;/span&gt; is not true," we can also write &lt;span class="math"&gt;\(\sim P = K\)&lt;/span&gt;: If the Ptolemaic system isn't right, then Kepler's is (and vice versa). Also, let's write &lt;span class="math"&gt;\(P(C)\)&lt;/span&gt; to mean "the probability of claim &lt;span class="math"&gt;\(C\)&lt;/span&gt;" and &lt;span class="math"&gt;\(P(C|E)\)&lt;/span&gt; to mean "the probability of claim &lt;span class="math"&gt;\(C\)&lt;/span&gt; given evidence &lt;span class="math"&gt;\(E\)&lt;/span&gt;."&lt;/p&gt;
&lt;p&gt;So initially we have a degree of confidence that Ptolemy's model is correct, which with our notation we can write as &lt;span class="math"&gt;\(P(P)\)&lt;/span&gt;, and likewise &lt;span class="math"&gt;\(P(K)\)&lt;/span&gt; is our initial probability that Kepler's model is correct. These probabilities are called "priors" because they represent our confidence before any new pieces of evidence (or observations) become available to us. We can represent the new observations as:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(O =\)&lt;/span&gt; Tycho Brahe has made very many precise observations that Kepler says can be modeled more simply with his framework; Galileo has discovered the law of inertia&lt;/p&gt;
&lt;p&gt;We're interested in &lt;span class="math"&gt;\(P(P|O)\)&lt;/span&gt; and &lt;span class="math"&gt;\(P(K|O)\)&lt;/span&gt;, the probabilities for each model given the new observations. Our initial confidence in the Ptolemaic model, before the new evidence is introduced, is probably pretty high, say &lt;span class="math"&gt;\(P(P) = 0.9\)&lt;/span&gt;; since the only other possibility is Kepler's model being correct, we have &lt;span class="math"&gt;\(P(K) = 0.1\)&lt;/span&gt; (the two probabilities have to sum to 1). &lt;/p&gt;
&lt;p&gt;We can represent this state of affairs in the rectangle on the far left in the tree-like figure below: 90% of that rectangle is shaded green; that part represents our confidence in P. The other 10% is shaded red, corresponding to our initial confidence that K is correct.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/bayes_tree.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;Branching off of that rectangle are two others, which each represent different possible epistemic universes: In the upper one, the Ptolemaic model is correct; in the lower universe Kepler's turns out to be right. Notice that the branches going to these rectangles are labeled with their respective probabilities, 0.9 and 0.1.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/left_side.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;Now let's look at the opposite side of the figure on the far right. To shade in this rectangle (which has gray shaded regions matching the one on the left that we started with), we have to ask ourselves about P(O|P) and P(O|K), the probabilities that the observations are correct in the different universes, one in which Ptolemy is right and the other in which Kepler is right. After all, maybe Tycho Brahe took all his observations while drunk and wrote the numbers down wrong, or maybe he made some kind of measurement error, or maybe Kepler's math is wrong!&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/right_side.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;The proportion of red in the bottom part of the rectangle represents &lt;span class="math"&gt;\(P(O|K)\)&lt;/span&gt;, the probability that the observations are correct in the universe where the planets do move, in fact, the way Kepler describes. It would be pretty unlikely that Brahe or Kepler made serious mistakes and yet the planets move on ellipses anyway! So we set &lt;span class="math"&gt;\(P(O|K) = 0.9\)&lt;/span&gt; (we would probably set it even higher, but let's keep the numbers nice and simple). The shaded red region is meant to take up 90% of the area in the bottom part of the rectangle; I drew it a little larger for clarity. &lt;/p&gt;
&lt;p&gt;The green shaded region of upper portion of the rectangle represents &lt;span class="math"&gt;\(P(O|P)\)&lt;/span&gt;, the probability that the observations are correct, but that Ptolemy's model is the correct one anyway. How might that happen? It turns out that if you add some extra epicycles - that is, make the planets travel on circles that are on circles, which then move around the Earth - you can get them to appear to move in the night sky just as Brahe's measurements indicate. &lt;/p&gt;
&lt;p&gt;Of course then that model starts to look clunky, so maybe we think that's not too likely to be correct. Let's set &lt;span class="math"&gt;\(P(O|P) = 0.1\)&lt;/span&gt;, then. If we imagine tiling the top part of the rectangle with 10 vertical strips, the green is just one of those strips, again drawn a bit larger than it would really look, for clarity.&lt;/p&gt;
&lt;p&gt;The two rectangles branching off toward the left from the one on the far right represent a universe in which the observations are correct (top branch) and one in which they are not (bottom branch). &lt;/p&gt;
&lt;p&gt;Now let's look more closely at the middle rectangles. They show the overlap between the ones on each side, the area they have in common. For example, the middle top rectangle has the green area that's in common between the rectangle connected to its left and the one connected to its right side; the middle rectangle second from the top contains green that represents the overlap between the two green areas in the rectangles to which it's connected, and so on.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/tree_middle.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;So far I haven't explained a lot of the numbers in the diagram. We start on the left, and use those numbers to get the ones on the right. The branch leading from the second upper rectangle to the upper middle one is labeled &lt;span class="math"&gt;\(P(O|P)=0.1\)&lt;/span&gt;. We are given that &lt;span class="math"&gt;\(P\)&lt;/span&gt; is true (remember, this branch represents a universe in which &lt;span class="math"&gt;\(P\)&lt;/span&gt; is true!) and are considering the probability that the observations are correct. This is precisely the probability that we represented on the far right rectangle by shading in 10% of its upper part. And here you can see that the thin green strip on the middle rectangle is 10% of the area of the one attached to its left. &lt;/p&gt;
&lt;p&gt;&lt;img src="./images/left_side_nums.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;Similarly, the green in the middle rectangle second from the top is 90% of the area of the green in the rectangle connected to its left side, so that branch is labeled &lt;span class="math"&gt;\(P(~O|P) = 0.9\)&lt;/span&gt;. Notice that &lt;/p&gt;
&lt;div class="math"&gt;$$
P(O|P) + P(\sim O|P) = 0.1 + 0.9 = 1,
$$&lt;/div&gt;
&lt;p&gt;and that's generally the case: The sum of two branches coming from the same rectangle must add up to 1. &lt;/p&gt;
&lt;p&gt;The probabilities on the tops of the middle rectangles are joint probabilities. For example, to get to the top rectangle, two things must happen: Ptolemy's model has to be correct, &lt;span class="math"&gt;\(P(P)=0.9\)&lt;/span&gt;, and then the observations have to be correct, given Ptolemy's model being correct, &lt;span class="math"&gt;\(P(O|P) = 0.1\)&lt;/span&gt;. So the probability of both these things happening is their product: &lt;/p&gt;
&lt;div class="math"&gt;$$
P(P)P(O|P) = 0.09. 
$$&lt;/div&gt;
&lt;p&gt;The other numbers along the middle are arrived at similarly. Now let's look at the right hand side again.&lt;/p&gt;
&lt;p&gt;&lt;img src="./images/right_side_nums.jpg" width="180"/&gt;&lt;/p&gt;
&lt;p&gt;The number on the upper branch coming from the far right rectangle is obtained by adding up the numbers on top of the rectangles that it ultimately connects to in the middle. That is,&lt;/p&gt;
&lt;div class="math"&gt;$$
P(O) = P(O\And P) + P(O\And K) = 
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
0.09 + 0.09 = 0.18.
$$&lt;/div&gt;
&lt;p&gt;Similarly,&lt;/p&gt;
&lt;div class="math"&gt;$$
P(\sim O) = P(\sim O \And P) + P(\sim O \And K) 
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
= 0.81 + 0.01 = 0.82.
$$&lt;/div&gt;
&lt;p&gt;Notice these two branches, since they both lead off the same rectangle, sum to 1: 0.18 + 0.82 = 1.&lt;/p&gt;
&lt;p&gt;Now what about the number in yellow, &lt;span class="math"&gt;\(P(P|O)\)&lt;/span&gt;? We get that one by noting that the number on the top of the middle rectangle has to be &lt;span class="math"&gt;\(P(O)P(P|O)\)&lt;/span&gt;, just like on the left side it was &lt;span class="math"&gt;\(P(P)P(O|P)\)&lt;/span&gt;. So if we call that yellow number &lt;span class="math"&gt;\(x\)&lt;/span&gt;, we have &lt;span class="math"&gt;\(P(O)x = P(O\And P)\)&lt;/span&gt; or &lt;span class="math"&gt;\(0.18x = 0.09\)&lt;/span&gt;. Solving this equation for x gives &lt;span class="math"&gt;\(x = 0.09/0.18 = 0.5\)&lt;/span&gt;. The other numbers on those branches are obtained the same way. For example, if we use a &lt;span class="math"&gt;\(y\)&lt;/span&gt; to represent the value on the bottom, labeled &lt;span class="math"&gt;\(P(K|~O)\)&lt;/span&gt;, we need to have &lt;span class="math"&gt;\(P(~O)y = P(~O\And K)\)&lt;/span&gt; or &lt;span class="math"&gt;\(0.82y = 0.01\)&lt;/span&gt;, so that &lt;span class="math"&gt;\(y = 0.01/0.82 = 0.01\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;So we started with confidence &lt;span class="math"&gt;\(P(P)=0.9\)&lt;/span&gt;, but after all that new science we find ourselves at &lt;span class="math"&gt;\(P(P)=0.5\)&lt;/span&gt;: We're not so sure anymore!&lt;/p&gt;
&lt;p&gt;It may seem like a lot, but once you get used to it, it doesn't take long to draw up a Bayes tree and think through your confidence update for a claim, given new evidence.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="simple tools"></category><category term="bayes' theorem"></category></entry><entry><title>simple tools, part 5: decision trees</title><link href="https://calculensis.github.io/decision%20trees.html" rel="alternate"></link><published>2022-08-06T00:00:00-04:00</published><updated>2022-08-06T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-08-06:/decision trees.html</id><summary type="html">&lt;p&gt;I describe how to use decision trees&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/decision-tree.jpg" width="150"/&gt;&lt;/p&gt;
&lt;p&gt;Now that we know, from &lt;a href="https://www.thedecisionblog.com/probability%20and%20degrees%20of%20belief.html"&gt;the previous post&lt;/a&gt;, how to translate back and forth between our degrees of confidence and subjective probabilities, we can learn a new tool that, unlike the &lt;a href="https://www.thedecisionblog.com/linear%20model.html"&gt;linear model&lt;/a&gt; or the &lt;a href="https://www.thedecisionblog.com/pro-con%20list.html"&gt;weighted pro-con list&lt;/a&gt;, takes into account the uncertainty of the outcomes of our actions.&lt;/p&gt;
&lt;p&gt;Before continuing, it's important to say that we'll often be considering simple versions of our models, because it's easier to explain how to use them if we keep it simple. But once you know how to use them, you can add sophistication in all sorts of ways. For example, the three factor linear model can have more than three factors; the tree we're about to describe can get very complicated indeed if that's what it takes to faithfully describe the situation that you're in!&lt;/p&gt;
&lt;p&gt;Now, then, say we're trying to consider whether to read that new book everyone is talking about. After all, reading it has an opportunity cost: Time you spend reading it is time that you could have spent doing something else, something perhaps more valuable to you. &lt;/p&gt;
&lt;p&gt;The decision tree for whether to read the book is shown below; here is how it's constructed: The square on the left hand side is called a "choice point"; the branches leading from it (sometimes called "levers") are the different things you could choose to do. In this example there are two branches, "read it" and "don't read it", but in general there could be any number of branches depending on how many options you're considering.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/read-or-not.png" width="300"/&gt;&lt;/p&gt;
&lt;p&gt;The circles represent points past which things are not under your control anymore: If you read the book, then you will either have learned something valuable or not (according to this model, though see below), each with a certain probability. Suppose you suspect that the book contains something valuable that you don't already know, maybe because a friend recommended it to you. &lt;/p&gt;
&lt;p&gt;Suspecting that you would learn something is in the neighborhood of 0.6; so we label the "learn" branch with that probability. The probabilities on all the branches leading from a given circle have to sum to 1 (because one of those things has to happen); so the probability on the "not learn" branch is 0.4.&lt;/p&gt;
&lt;p&gt;We have been assuming that only two branches lead from each of the circles to keep things simple, but they can be any number depending on the number of different outcomes we're considering. For example, we could have made three branches, one for "learn something of great value", one for "learn something moderately useful", and one for "learn nothing useful". Again, whatever numbers we put for the probabilities of these outcomes, they would all need to sum to 1.&lt;/p&gt;
&lt;p&gt;The lower circle also has two possible outcomes: You didn't read it and missed out on something important, or you didn't read it and didn't miss out on anything. If the probability of learning something useful from the book is 0.6, it makes sense that the probability of missing out if you don't read it would be the same, 0.6, but the probabilities on the lower part of the tree don't always have to be the same as on the upper part. It just turns out that way for this example.&lt;/p&gt;
&lt;p&gt;The last ingredients are the numbers at the ends of the branches. These are called "utilities" or "personal values", and they represent how good or how bad each outcome would be, with the worst outcome getting 0 and the best getting 100. &lt;/p&gt;
&lt;p&gt;The worst outcome is spending the time to read the book and getting nothing out of it, so that branch gets 0. The best outcome, let's say, is reading the book and learning something valuable from it (the value of the thing you learned being much greater than the opportunity cost you incurred reading). This outcome gets 100. &lt;/p&gt;
&lt;p&gt;Not reading it and missing out on what the book has to teach you is bad, but not as bad as reading it and getting nothing would be, so that branch gets a 10. This number you get by asking your gut how bad it would be on a scale from 0 to 100. Again consulting our guts, suppose we decide that not reading the book and not missing out on anything should get a 90. (It's not as good as if we had read it and learned something!)&lt;/p&gt;
&lt;p&gt;After the tree is constructed, we calculate "expected utilities" for each choice as shown on the right hand side: For each branch leading from the choice point, multiply the probability times the personal value and add it all up. The choice that has the highest expected utility wins, in this case the "read it" branch.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry><entry><title>simple tools, part 4: probability and degrees of belief</title><link href="https://calculensis.github.io/probability%20and%20degrees%20of%20belief.html" rel="alternate"></link><published>2022-08-05T00:00:00-04:00</published><updated>2022-08-05T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-08-05:/probability and degrees of belief.html</id><summary type="html">&lt;p&gt;I describe how to map beliefs to probabilities&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/dice.jpg" width="150"/&gt;&lt;/p&gt;
&lt;p&gt;Before we start, an admission: The things in this post are not so much useful in themselves as prerequisites for things we're going to do later. For many of the tools that follow, we'll need to be able to assign numbers to our subjective degrees of confidence. By the end of this post, you'll know how we're going to do that!&lt;/p&gt;
&lt;p&gt;Suppose we're trying to decide whether to found a startup, and that the probability of success of a randomly chosen startup is 10% (numbers like this often come from historical frequency data). To make the math work out right for the models I'll be introducing later, we'll divide by 100 and represent probabilities as numbers between 0 and 1 instead of between 0 and 100.&lt;/p&gt;
&lt;p&gt;If our startup were like a randomly chosen one, then, we would estimate our probability of success at 0.1. This probability, which we get before taking into account the details of our own particular circumstances, is called the base rate or prior probability; it comes from Bayesian probability theory (on which more later).&lt;/p&gt;
&lt;p&gt;At this point we could look up the most common reasons that startups fail and then take steps to make those outcomes less probable. For example, running out of money is a common reason; to mitigate that possibility, we could work extra hard securing investors. We might also make extra sure that we did our due diligence with market analysis, etc. Suppose we did all this. Now we can update our prior to... what?&lt;/p&gt;
&lt;p&gt;What we need is a way to map our new (albeit squishy and gut-derived) degree of confidence to a probability; we can do it via the following reasoning: Consider flipping a fair coin. It has probability 0.5 of landing heads and 0.5 of landing tails. If I asked you, before flipping, "Do you think the coin will land heads?", an answer that would make tons of sense is "I have no idea, it's equally likely to come up either way!" From this we conclude that 0.5 corresponds to taking no position, that is, not believing either way about the truth of some possibility. &lt;/p&gt;
&lt;p&gt;Now suppose that the coin is weighted so that it lands heads 60% of the time. In this case a reasonable answer to the question of which side in will land on is "I suspect it will land heads, because it's a little more likely to do that." By now, you see where this line of reasoning is going: Probabilities between 0.5 and 1 represent increasing degrees of confidence that a thing will happen, and between 0.5 and 0 represent degrees of confidence that it won't. &lt;/p&gt;
&lt;p&gt;Returning to our problem: What is the probability corresponding to our degree of confidence of success now that we've taken precautions? Our starting value of 0.1 is a lot closer to zero than it is to 0.5, so it corresponds to being highly confident that the business will fail (i.e., highly confident that it won't succeed). How much should we increase that number for our particular case? It's a difficult question, about which much ink or, erm, pixels can be spilled. Let's say you only suspect failure. If 0.6 is suspecting success, then 0.4 should be suspecting failure, so our updated degree of confidence that the business will succeed is 0.4.&lt;/p&gt;
&lt;p&gt;That's how it works! Here is a scale with suggested degrees of belief attached:&lt;/p&gt;
&lt;p&gt;&lt;img src="images/probability-scale.png" width="400"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry><entry><title>simple tools, part 3: the weighted pro-con list</title><link href="https://calculensis.github.io/pro-con%20list.html" rel="alternate"></link><published>2022-07-27T00:00:00-04:00</published><updated>2022-07-27T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-07-27:/pro-con list.html</id><summary type="html">&lt;p&gt;I describe the weighted pro-con list&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/journal-coffee.jpg" width="150"/&gt;&lt;/p&gt;
&lt;p&gt;The linear model directs us to condense our decision down to the few most important things, but that can be difficult or not feasible; what then? One answer to that question is the weighted pro-con list. &lt;/p&gt;
&lt;p&gt;It goes like this: For each possibility that you're considering, write down a list of good things that would happen (pros) and bad things (cons) underneath it. Now you've got an ordinary pro-con list.&lt;/p&gt;
&lt;p&gt;The next step is, for each item you wrote as a pro, rate the goodness of that item on a scale from 0 (not good at all) to 10 (maximally good). Similarly, rate the cons, except this time use negative numbers, so something moderately bad would get, e.g., a -5. &lt;/p&gt;
&lt;p&gt;&lt;img src="images/weighted-pro-con.png" width="350"/&gt;&lt;/p&gt;
&lt;p&gt;Once all the pro-con items for an action under consideration have scores, you add them all up, both negative and positive; do that separately for each choice you're considering. An example is shown for the decision of "whether to leave my current job." The choice that ends up with the highest score is the one to choose, according to this model; in the example shown, the model says that you should leave your current job.&lt;/p&gt;
&lt;p&gt;Just like with the linear model, you may find yourself unhappy with the final result; again, you will have learned something about how you feel. This would also be an excellent opportunity to understand your feelings better by figuring out why the pro-con model ended up giving the "wrong" result. Maybe the weights aren't quite right. Maybe you missed an important pro or con.&lt;/p&gt;
&lt;p&gt;For example, suppose you are unhappy with the verdict that you should change jobs. In this case I would first apply the status quo bias test, designed to make sure that we aren't valuing our current situation too much just because we happen to already be in it. This test asks you to imagine yourself, as vividly as possible, already at the new job and then ask "If there were a button I could press that would make things go back to the way they are now, would I press it?" Your answer to this question can reveal what your preferences would be subtracting out the status quo bias. After that, if the problem is still not resolved, you might return to the pros, cons, and their weights.&lt;/p&gt;
&lt;p&gt;So far we've been treating the consequences of our decisions as certain. For example, the pro-con list for the example pictured above assumes that "I would love what I do" would definitely happen if you took the new job. But what if we want to incorporate uncertainty into our thinking? Stay tuned!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry><entry><title>simple tools, part 2: the linear model</title><link href="https://calculensis.github.io/linear%20model.html" rel="alternate"></link><published>2022-07-20T00:00:00-04:00</published><updated>2022-07-20T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-07-20:/linear model.html</id><summary type="html">&lt;p&gt;I describe the linear model for decision making&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/arrow.jpg" width="150"/&gt;&lt;/p&gt;
&lt;p&gt;For our first simple decision making tool, let's look at the 2 to 3 factor linear model. Suppose you're trying to decide which of two houses to buy, &lt;span class="math"&gt;\(H_1\)&lt;/span&gt; or &lt;span class="math"&gt;\(H_2\)&lt;/span&gt;, and you're really on the fence about it! &lt;/p&gt;
&lt;p&gt;The linear model approach asks you first to consider what are the 2 or 3 most important attributes for you that a potential home could have. For example, let's say they are affordability of monthly payment (A), that feeling of charm when you first walk in (C), and typical level of quietness (Q). Granted, this last attribute might be hard to get at, but knowing that it's one of the most important qualities for you would be important, and it could get you thinking of ways you might determine it, perhaps by interviewing some of your new would-be neighbors.&lt;/p&gt;
&lt;p&gt;The next step is to decide how important these attributes are relative to one another and assign them weights; let's call them &lt;span class="math"&gt;\(w_A\)&lt;/span&gt;, &lt;span class="math"&gt;\(w_C\)&lt;/span&gt;, and &lt;span class="math"&gt;\(w_Q\)&lt;/span&gt;. The weights will be numbers between 0 and 1 such that when you add them together you get 1. For example, if each of the above attributes is equally important to you, then they all get weight 1/3. Or if, say, affordable monthly payment is twice as important as level of quietness, and quietness is just as important as the charm factor, you would have &lt;span class="math"&gt;\(w_A=2/4\)&lt;/span&gt;, &lt;span class="math"&gt;\(w_C=1/4\)&lt;/span&gt;, and &lt;span class="math"&gt;\(w_Q=1/4\)&lt;/span&gt;. You may have to play around to find the right values, but you can always just guess, see if the weights sum to 1, and adjust as needed. For the rest of our house example, let's use the weights &lt;span class="math"&gt;\(w_A=2/4\)&lt;/span&gt;, &lt;span class="math"&gt;\(w_C=1/4\)&lt;/span&gt;, and &lt;span class="math"&gt;\(w_Q=1/4\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now you would rate homes &lt;span class="math"&gt;\(H_1\)&lt;/span&gt; and &lt;span class="math"&gt;\(H_2\)&lt;/span&gt; based on the attributes, where each attribute gets a score from 0 (worst) to 10 (best). For example, maybe &lt;span class="math"&gt;\(H_1\)&lt;/span&gt; is a super affordable house in a moderately quiet neighborhood; in that case, you might might score it as A = 9 and Q = 7. Maybe it's not so high on charm, so C = 3. The linear model we've been constructing would then have us calculate a total score &lt;span class="math"&gt;\(S(H_1)\)&lt;/span&gt; for house 1 using the formula&lt;/p&gt;
&lt;div class="math"&gt;$$
S(H_1) = w_A A + w_C C + w_Q Q 
$$&lt;/div&gt;
&lt;div class="math"&gt;$$
=\frac{2}{4}(9)+\frac{1}{4}(3)+\frac{1}{4}(7)=7.
$$&lt;/div&gt;
&lt;p&gt;Suppose the second potential home is charming indeed (C=9) but not so affordable (A=3), and that it's in a medium-noise environment (Q=5). Then we get&lt;/p&gt;
&lt;div class="math"&gt;$$
S(H_2) = \frac{2}{4}(3)+\frac{1}{4}(9)+\frac{1}{4}(5)=5,
$$&lt;/div&gt;
&lt;p&gt;and the model says to buy the first home, &lt;span class="math"&gt;\(H_1\)&lt;/span&gt;, because it scores higher.&lt;/p&gt;
&lt;p&gt;What if you find yourself not liking that result? Then you can try to figure out why your feelings and the model disagree. Maybe those weights weren't quite right? Maybe the attributes you chose weren't the most important ones to you after all? And if, no matter what you do, you keep finding yourself unhappy when &lt;span class="math"&gt;\(H_1\)&lt;/span&gt; wins, then the model helped you discover how you feel, and you still learned something significant. (Remember, you were on the fence at first!) &lt;/p&gt;
&lt;p&gt;The next model I present will complement this one.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry><entry><title>simple tools, part 1</title><link href="https://calculensis.github.io/simple%20tools.html" rel="alternate"></link><published>2022-07-17T00:00:00-04:00</published><updated>2022-07-17T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-07-17:/simple tools.html</id><summary type="html">&lt;p&gt;Part of a series on simple tools&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/linear.jpg" width="200"/&gt;&lt;/p&gt;
&lt;p&gt;It seems like there are two extreme intuitions that are commonly held about how best to go about decision making: The first is to say "The hell with models - I can do just fine by myself!" and the second is "Sure I can use some help, and the more sophisticated the better! And by sophisticated, I mean AI." &lt;/p&gt;
&lt;p&gt;Both of these ideas reject using simple pencil-and-paper models, to their detriment! I'll explain why for each in turn.&lt;/p&gt;
&lt;p&gt;Regarding the first idea - that we do just fine by ourselves - there are many factors mitigating against this notion, but in the interest of space I'll focus on just two: the recency effect and incomplete thinking. &lt;/p&gt;
&lt;p&gt;The recency effect is our tendency to give whatever we were thinking about most recently a greater weight than other factors that we want to influence our decision. So, for example, to decide where we want to go for vacation, suppose we care about affordability and location. If the last thing we were considering is location, then affordability likely won't get as much weight as it deserves when we are making our final decision. &lt;/p&gt;
&lt;p&gt;Again, if we are taking a multi-lens approach - that is, looking at the decision from many different perspectives - then we run the risk of giving the last lens we looked through more power than it deserves. &lt;/p&gt;
&lt;p&gt;Incomplete thinking can refer to not generating enough possibilities, i.e. failing at step one of &lt;a href="https://www.thedecisionblog.com/decisions%20and%20the%20search-inference%20framework.html"&gt;the search-inference framework&lt;/a&gt;, but it also happens when we don't think through each of the possibilities we've generated thoroughly enough. Exacerbating this problem is that it usually feels to us like we're considering everything we need to, like something more complicated is going on in our minds than really is. &lt;/p&gt;
&lt;p&gt;This feeling - that we are always doing a good job integrating the information available to us - is similar to the feeling that we experience the full panoply of information about what lies in front of us through the light that reaches our eyes: In reality we only see a small part of that information; our brains fill in the gaps in a way that is usually correct but fools us into thinking that we have a much richer perception of the world than we do.&lt;/p&gt;
&lt;p&gt;We can overcome the recency effect, and to a large extent incomplete thinking, by using pencil-and-paper math models. Such models will maintain the proper weights because those weights will be contained in the model equations; moreover, the models will guide us to think all the way through the relevant possibilities.&lt;/p&gt;
&lt;p&gt;Another important consideration is that decisions often seem to involve a lot of variables, and to get anywhere it helps to try and boil these dimensions down to just a few things that matter the most; making a model often forces us to go through that process. It's true that AI can also help us simplify things this way...&lt;/p&gt;
&lt;p&gt;...which brings us to the second of the extreme intuitions: That the only thing that will do better than we do is something computationally sophisticated like machine learning (a type of AI). For many decisions we don't have time to collect months worth of data (or spend time trying to find and clean data that may already be out there somewhere) and run analytics on it. In fact, for many decisions we don't even start out knowing what data would be relevant or what questions we would want to ask of that data!&lt;/p&gt;
&lt;p&gt;A middle approach is to do something that improves on our native mental abilities but that doesn't involve computation - in other words, pencil-and-paper modeling.&lt;/p&gt;
&lt;p&gt;In the next few posts I'll share some of these models with you!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry><entry><title>decisions and the search-inference framework</title><link href="https://calculensis.github.io/decisions%20and%20the%20search-inference%20framework.html" rel="alternate"></link><published>2022-07-11T00:00:00-04:00</published><updated>2022-07-11T00:00:00-04:00</updated><author><name>Kayla Lewis</name></author><id>tag:calculensis.github.io,2022-07-11:/decisions and the search-inference framework.html</id><summary type="html">&lt;p&gt;Why multi-model decision making is so important&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align=right src="images/choosing.jpg" width="200"/&gt;&lt;/p&gt;
&lt;p&gt;Hello everyone, welcome to my first blog entry!&lt;/p&gt;
&lt;p&gt;This blog will be about all things related to effective decision making. &lt;/p&gt;
&lt;p&gt;I'm going to start with simpler approaches or models that don't take very much time and build up to the more sophisticated ones.&lt;/p&gt;
&lt;p&gt;A common theme will be that looking at a decision through as many lenses as possible, given our time constraints, is extremely useful; in this first post I want to explain why that is.&lt;/p&gt;
&lt;p&gt;Making decisions is a kind of thinking, and one of my favorite models describing how thinking works is the search-inference framework. As applied to decision making, it says that thinking has three stages:&lt;/p&gt;
&lt;p&gt;(1) We generate a space of possible actions or vantage points&lt;/p&gt;
&lt;p&gt;(2) By using the evidence currently available to us, and in light of our goals, we evaluate the strength of each possibility&lt;/p&gt;
&lt;p&gt;(3) We choose, or infer, the strongest possibility&lt;/p&gt;
&lt;p&gt;The most common mistakes in thinking can be traced to failing at step (1) or (2). For step (1), the common failure is not generating a rich enough space of possibilities; for step (2), it's not weighing the evidence for each possibility fairly. I'll talk about this second way of failing in later posts.&lt;/p&gt;
&lt;p&gt;Viewing a decision through multiple lenses or models is a way of lowering the probability that we fail at step (1): Each model gives us a different way of viewing the decision we want to make.&lt;/p&gt;
&lt;p&gt;Very often, different models will tell us to take different courses of action. It might seem like this is a problem, but in reality it's a strength. Instead of hoping that all models will give the same answer, what we'll do is try to understand &lt;strong&gt;&lt;em&gt;why&lt;/em&gt;&lt;/strong&gt; the different approaches give the answers that they do; in so doing, it will usually become clearer which choice we ultimately want to make.&lt;/p&gt;
&lt;p&gt;You can think of asking models what they "think" just as you would ask your friends what they think. Your friends might give conflicting answers, and that's a good thing! You are definitely expanding the space of possibilities to consider when that happens.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;amp;t=YFPoxpEQ2Qp14U4FliD7fA"&gt;Discuss on Twitter&lt;/a&gt;&lt;/p&gt;</content><category term="simple tools"></category><category term="simple tools"></category></entry></feed>