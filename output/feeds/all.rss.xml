<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>the decision blog</title><link>https://calculensis.github.io/</link><description></description><lastBuildDate>Mon, 11 Jul 2022 00:00:00 -0400</lastBuildDate><item><title>decisions and the search-inference framework</title><link>https://calculensis.github.io/decisions%20and%20the%20search-inference%20framework.html</link><description>&lt;p&gt;&lt;img align=right src="images/choosing.jpg" width="200" height="200" /&gt;&lt;/p&gt;
&lt;p&gt;Hello everyone, welcome to my first blog entry!&lt;/p&gt;
&lt;p&gt;This blog will be about all things related to effective decision making. &lt;/p&gt;
&lt;p&gt;I'm going to start with simpler approaches or models that don't take very much time and build up to the more sophisticated ones.&lt;/p&gt;
&lt;p&gt;A common theme will be that looking at a decision through as many lenses as possible, given our time constraints, is extremely useful; in this first post I want to explain why that is.&lt;/p&gt;
&lt;p&gt;Making decisions is a kind of thinking, and one of my favorite models describing how thinking works is the search-inference framework. As applied to decision making, it says that thinking has three stages:&lt;/p&gt;
&lt;p&gt;(1) We generate a space of possible actions or vantage points&lt;/p&gt;
&lt;p&gt;(2) By using the evidence currently available to us, and in light of our goals, we evaluate the strength of each possibility&lt;/p&gt;
&lt;p&gt;(3) We choose, or infer, the strongest possibility&lt;/p&gt;
&lt;p&gt;The most common mistakes in thinking can be traced to failing at step (1) or (2). For step (1), the common failure is not generating a rich enough space of possibilities; for step (2), it's not weighing the evidence for each possibility fairly. I'll talk about this second way of failing in later posts.&lt;/p&gt;
&lt;p&gt;Viewing a decision through multiple lenses or models is a way of lowering the probability that we fail at step (1): Each model gives us a different way of viewing the decision we want to make.&lt;/p&gt;
&lt;p&gt;Very often, different models will tell us to take different courses of action. It might seem like this is a problem, but in reality it's a strength. Instead of hoping that all models will give the same answer, what we'll do is try to understand &lt;strong&gt;&lt;em&gt;why&lt;/em&gt;&lt;/strong&gt; the different approaches give the answers that they do; in so doing, it will usually become clearer which choice we ultimately want to make.&lt;/p&gt;
&lt;p&gt;You can think of asking models what they "think" just as you would ask your friends what they think. Your friends might give conflicting answers, and that's a good thing! You are definitely expanding the space of possibilities to consider when that happens.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kayla Lewis</dc:creator><pubDate>Mon, 11 Jul 2022 00:00:00 -0400</pubDate><guid isPermaLink="false">tag:calculensis.github.io,2022-07-11:/decisions and the search-inference framework.html</guid><category>basics</category><category>basics</category><category>search-inference</category></item></channel></rss>