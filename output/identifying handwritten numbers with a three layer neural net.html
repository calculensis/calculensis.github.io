<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <title>    identifying handwritten numbers with a three layer neural net
</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href='https://fonts.googleapis.com/css?family=Gentium+Book+Basic|Merriweather:400,300' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="https://calculensis.github.io/theme/css/cid.css">
        <link href="https://calculensis.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="the decision blog Atom Feed" />
        <link href="https://calculensis.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="the decision blog RSS Feed" />
    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

            <div class="container">

<header class="blog-header">
    <h1><a href="https://calculensis.github.io">the decision blog</a></h1>
    <p></p>
    <nav>
        <a href="https://calculensis.github.io/">INDEX</a>
        <a href="https://calculensis.github.io/archives">ARCHIVES</a>
        <a href="https://calculensis.github.io/categories">CATEGORIES</a>
    </nav>
</header>

    <div class="post">

        <header>
            <h1>identifying handwritten numbers with a three layer neural net</h1>
            <p class="date">Written on <time datetime="2023-02-08T00:00:00-05:00">Feb 08, 2023</time></p>
        </header>

        <article>
            <p><img align=right src="images/numbers_track.jpg" width="150"/></p>
<p>In this post, we'll create a three layer neural net for identifying handwritten numbers; to keep it from overfitting, we'll use a technique known as dropout. First, let's have a look at the data.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_digits</span>

<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
<span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>(1797, 8, 8)
</code></pre></div>

<p>We have 1797 handwritten numbers, each represented by 8x8=64 pixels; here's a plot showing some of them:</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;xticks&#39;</span><span class="p">:[],</span> <span class="s1">&#39;yticks&#39;</span><span class="p">:[]})</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;binary&#39;</span><span class="p">,</span><span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
</code></pre></div>

<p><img alt="png" src="./images/number_images.png"></p>
<p>For each number, we'll convert its 8x8 matrix of pixel values into an array of length 64; then we'll feed those numbers into layer 0 of our neural net. The next, hidden layer, will contain 200 neurons, and the output layer will contain 10 neurons, the first corresponding to the number 0, the second to 1, and so on up to 9. The output numbers will be "one-hot" encoded so, for example, if the number we feed in is 4 the neural net will ideally output the array [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]. We start by getting our data into the proper form as well as setting up the variables and activation functions that our neural net will need.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="c1"># normalize the data, hot-one encode the target data; create </span>
<span class="c1"># training and test sets</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span>
<span class="n">y_pre</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y_pre</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_pre</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">y_pre</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">=</span><span class="mf">1.0</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="o">-</span><span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">X</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># initialize weights and layers for a 3 layer neural net</span>
<span class="c1"># for which all biases are set to zero</span>
<span class="n">num_inputs</span>   <span class="o">=</span> <span class="mi">64</span>
<span class="n">num_outputs</span>  <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_layer</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">layer_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">num_inputs</span><span class="p">))</span>
<span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">hidden_layer</span><span class="p">))</span>
<span class="n">layer_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">num_outputs</span><span class="p">))</span>
<span class="n">weights_01</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span><span class="n">hidden_layer</span><span class="p">))</span><span class="o">-</span><span class="mf">1.0</span>
<span class="n">weights_12</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">hidden_layer</span><span class="p">,</span><span class="n">num_outputs</span><span class="p">))</span><span class="o">-</span><span class="mf">1.0</span>

<span class="c1"># define the activation functions and their derivatives</span>
<span class="c1"># layer_num = 1 will return the function for layer 1 and </span>
<span class="c1"># layer_num = 2 will return that for layer 2</span>
<span class="k">def</span><span class="w"> </span><span class="nf">activ_func</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">layer_num</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">layer_num</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">layer_num</span><span class="o">==</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">activ_deriv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">layer_num</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">layer_num</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mf">2.0</span>
    <span class="k">elif</span> <span class="p">(</span><span class="n">layer_num</span><span class="o">==</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">soft_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">soft_max</span><span class="o">*</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">soft_max</span><span class="p">)</span>
</code></pre></div>

<p>Now we let the neural net learn from the data but, to keep it from overlearning (that is, memorizing details that are not relevant for detecting the overall patterns), we randomly set half the neurons of the hidden layer to zero before each backpropagation step and we double the other ones to compensate for the missing half of the signal from that layer.</p>
<div class="highlight"><pre><span></span><code><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">max_iter</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">err_tol</span>  <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">err</span> <span class="o">=</span> <span class="mf">1000.0</span>
<span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># toggle dropout on or off</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">while</span> <span class="p">((</span><span class="nb">iter</span><span class="o">&lt;</span><span class="n">max_iter</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">err</span><span class="o">&gt;</span><span class="n">err_tol</span><span class="p">)):</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Xtrain</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">layer_0</span> <span class="o">=</span> <span class="n">Xtrain</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_inputs</span><span class="p">)</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">activ_func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span><span class="n">weights_01</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dropout</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">dropout_mask</span> <span class="o">=</span> \
                    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">layer_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">layer_1</span> <span class="o">*=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">dropout_mask</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">activ_func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span><span class="n">weights_12</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">delta</span> <span class="o">=</span> <span class="n">layer_2</span><span class="o">-</span><span class="n">ytrain</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">deriv_vec2</span>   <span class="o">=</span> <span class="n">activ_deriv</span><span class="p">(</span><span class="n">layer_2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">deriv_diag2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">deriv_vec2</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="n">gradient_12</span>  <span class="o">=</span> \
                <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span><span class="n">deriv_diag2</span><span class="p">))</span>
        <span class="n">deriv_vec1</span>   <span class="o">=</span> <span class="n">activ_deriv</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">deriv_diag1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">deriv_vec1</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">dropout</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">dropout_diag</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">dropout_mask</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="n">deriv_diag1</span> <span class="o">*=</span> <span class="n">dropout_diag</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weights_12</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">deriv_diag1</span><span class="p">)</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">deriv_diag2</span><span class="p">,</span><span class="n">omega</span><span class="p">)</span>
        <span class="n">delta_omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span><span class="n">omega</span><span class="p">)</span>
        <span class="n">gradient_01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span><span class="n">delta_omega</span><span class="p">)</span>

        <span class="n">weights_12</span> <span class="o">-=</span> <span class="n">alpha</span><span class="o">*</span><span class="n">gradient_12</span>
        <span class="n">weights_01</span> <span class="o">-=</span> <span class="n">alpha</span><span class="o">*</span><span class="n">gradient_01</span>

        <span class="n">err</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">delta</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">err</span> <span class="o">/=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="p">(</span><span class="nb">iter</span><span class="o">&lt;</span><span class="n">max_iter</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;converged at iteration: &quot;</span><span class="p">,</span><span class="nb">iter</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average error: &quot;</span><span class="p">,</span><span class="n">err</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;failed to converge&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>converged at iteration:  11
average error:  0.009976326528757164
</code></pre></div>

<p>Now we see how well our model can predict numbers for the test set.</p>
<div class="highlight"><pre><span></span><code><span class="n">err</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">layer_0</span> <span class="o">=</span> <span class="n">Xtest</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_inputs</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">activ_func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span><span class="n">weights_01</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">activ_func</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span><span class="n">weights_12</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ypred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer_2</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">layer_2</span><span class="o">-</span><span class="n">ytest</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">err</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">delta</span><span class="o">**</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">layer_2</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">==</span><span class="n">ytest</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
        <span class="n">num_correct</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">err</span> <span class="o">/=</span> <span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average test set error:&quot;</span><span class="p">,</span><span class="n">err</span><span class="p">)</span>
<span class="n">frac_correct</span> <span class="o">=</span> <span class="n">num_correct</span><span class="o">/</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;percent correct:&quot;</span><span class="p">,</span><span class="n">frac_correct</span><span class="o">*</span><span class="mf">100.0</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>average test set error: 0.06930050980970036
percent correct: 95.33333333333334
</code></pre></div>

<p>Our neural net predicts about 95% of the test set numbers correctly. Let's plot the confusion matrix for our current predictions, and set to -1 any output for which the model fails to select a number.</p>
<div class="highlight"><pre><span></span><code><span class="n">pred_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">test_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Xtest</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ypred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="n">pred_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">ypred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pred_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">test_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">ytest</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_array</span><span class="p">,</span><span class="n">pred_array</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int64&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> \
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> \
            <span class="n">yticklabels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;true label&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;predicted label&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code>Text(109.44999999999997, 0.5, &#39;predicted label&#39;)
</code></pre></div>

<p><img alt="png" src="./images/number_confusion.png"></p>
<p>We can see, e.g., that one time the correct answer was 4, while the model was unable to select any number. On the other hand, it correctly identified 3 as such 31 times. The derivations for the backpropagation equations are instructive but a bit involved, so I'll provide those in the next post.</p>
<p><a href="https://twitter.com/Estimatrix/status/1555693184977600512?s=20&amp;t=YFPoxpEQ2Qp14U4FliD7fA">Discuss on Twitter</a></p>
        </article>

        <footer>
            <p>This entry is posted in <a href="https://calculensis.github.io/category/machine-learning.html">machine learning</a>.</p>
        </footer>


    </div>


<footer class="blog-footer">

    <ul class="nav">
    </ul>

    <p class="disclaimer">
    Built with <a href="http://getpelican.com">Pelican</a>, and <a href="https://github.com/hdra/Pelican-Cid">Cid</a> theme.
    </p>
</footer>
            </div>
<script>
    var _gaq=[['_setAccount','UA-234119846-1'],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
    </body>
</html>